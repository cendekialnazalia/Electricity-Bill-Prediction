# -*- coding: utf-8 -*-
"""Electricity Bill Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sAsCM4XIJfm50GCQPnocCcSnBOEX10c3

# IMPORT LIBRARY

### Import Library untuk Data Manipulasi dan Visualisasi
Pada tahap ini, kita mengimpor library yang digunakan untuk membaca, mengolah,
serta memvisualisasikan data.

- **pandas (pd)** digunakan untuk membaca dan mengelola data dalam bentuk tabel (DataFrame).
- **numpy (np)** digunakan untuk perhitungan numerik, seperti operasi array atau fungsi matematis.
- **matplotlib.pyplot (plt)** digunakan untuk membuat visualisasi dasar seperti grafik garis, bar, atau scatter plot.
- **seaborn (sns)** digunakan untuk membuat visualisasi yang lebih informatif dan estetik.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

"""### Import Library untuk Pemodelan Machine Learning
Tahap ini menyiapkan library dari scikit-learn yang akan digunakan untuk membuat model prediksi.

- **train_test_split** digunakan untuk membagi dataset menjadi data latih (training) dan data uji (testing).
- **LinearRegression** adalah algoritma regresi sederhana yang mencoba memodelkan hubungan linier antara fitur dan target.
- **RandomForestRegressor** adalah algoritma berbasis *ensemble learning* dengan banyak decision tree untuk memprediksi nilai target secara lebih kompleks.

"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor

"""### Import Library untuk Evaluasi Model
Setelah model dilatih, kita perlu menilai performanya.
Tahap ini mengimpor metrik evaluasi untuk mengukur seberapa baik model dalam melakukan prediksi.

- **mean_absolute_error (MAE)** → mengukur rata-rata error absolut.
- **mean_squared_error (MSE)** → mengukur rata-rata error kuadrat (memberi penalti lebih besar pada error besar).
- **r2_score (R²)** → mengukur seberapa baik model menjelaskan variasi data (semakin mendekati 1, semakin baik).

"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

"""### Load Dataset dari Google Drive
Pada tahap ini, dataset yang disimpan di Google Drive akan diakses dan dimuat ke dalam program menggunakan **pandas**.  
Langkah-langkah yang dilakukan:
1. **Menyimpan URL file Google Drive** dalam variabel `url`.  
   URL ini adalah link *sharing* dari Google Drive.
2. **Mengambil file ID** dari link. Pada link Google Drive, bagian `/d/<file_id>/` adalah identitas unik file.
3. **Membuat direct download link** menggunakan format `https://drive.google.com/uc?id=<file_id>` agar file bisa diunduh langsung oleh pandas.
4. **Membaca dataset** menggunakan `pd.read_csv()` dan menyimpannya dalam variabel `consumption`.  
   Dataset kini siap digunakan untuk eksplorasi dan analisis.

"""

# link file di Google Drive
url = 'https://drive.google.com/file/d/1COGBPHhANXxutOp7c4lzS6VsovBL0HeF/view?usp=sharing'

# ambil file ID dari link
file_id = url.split('/d/')[1].split('/')[0]

# buat direct download link
dwn_url = f'https://drive.google.com/uc?id={file_id}'

# load dataset
consumption = pd.read_csv(dwn_url)

consumption

"""# EXPLORATORY DATA ANALYSIS

### Melihat Struktur Dataset
Pada tahap ini, kita menggunakan fungsi `info()` dari pandas untuk melihat gambaran umum dataset.  
Informasi yang ditampilkan meliputi:
- Jumlah baris dan kolom.
- Nama setiap kolom.
- Jumlah data non-null (apakah ada nilai kosong/missing).
- Tipe data pada setiap kolom (integer, float, object/string, dll).
- Total penggunaan memory dataset.

Langkah ini penting untuk memastikan dataset terbaca dengan baik dan memahami tipe data sebelum dilakukan analisis lebih lanjut.
"""

consumption.info()

"""### Statistik Deskriptif Dataset
Pada tahap ini digunakan fungsi `describe()` dari pandas untuk melihat ringkasan statistik dari setiap kolom numerik.  

Informasi yang ditampilkan antara lain:
- **count** → jumlah data non-missing pada kolom.
- **mean** → nilai rata-rata.
- **std** → standar deviasi (penyebaran data).
- **min** → nilai terkecil.
- **25% (Q1)** → kuartil pertama (25% data berada di bawah nilai ini).
- **50% (median)** → nilai tengah.
- **75% (Q3)** → kuartil ketiga (75% data berada di bawah nilai ini).
- **max** → nilai terbesar.

Langkah ini penting untuk memahami distribusi awal data, mendeteksi outlier, dan mengetahui rentang nilai dari setiap variabel numerik.

"""

consumption.describe()

"""### Mengecek Missing Values
Pada tahap ini digunakan fungsi `isnull().sum()` untuk menghitung jumlah nilai kosong (missing values) pada setiap kolom dataset.  

Langkah ini penting untuk:
- Mengetahui apakah ada data yang hilang.
- Menentukan strategi penanganan, misalnya: menghapus baris/kolom, atau mengganti nilai kosong dengan rata-rata/median/modus.  

Jika hasil menunjukkan **0**, berarti tidak ada data yang hilang. Jika ada nilai >0, maka perlu dilakukan *data cleaning* lebih lanjut.

"""

print("Missing values:\n", consumption.isnull().sum())

"""### Visualisasi Hubungan Antar Variabel (Pairplot)
Pada tahap ini digunakan fungsi `sns.pairplot()` dari seaborn untuk menampilkan grafik hubungan antar variabel numerik dalam dataset.  

Pairplot akan:
- Membuat scatter plot untuk setiap pasangan variabel → membantu melihat hubungan (linear/non-linear) antar fitur.
- Membuat histogram/diagonal plot untuk distribusi masing-masing variabel.
  
Visualisasi ini bermanfaat untuk:
- Menemukan pola hubungan antar variabel (misalnya semakin besar `housearea`, semakin tinggi `consumption`).
- Mengidentifikasi outlier atau nilai ekstrem.
- Memberikan gambaran awal sebelum membangun model regresi.

"""

sns.pairplot(consumption)
plt.show()

"""# DATA PREPARATION

### Menentukan Fitur (X) dan Target (y)
Pada tahap ini, dataset dipisahkan menjadi:
- **Target (`y`)** → variabel yang ingin diprediksi, yaitu `amount_paid`.  
  Target ini berisi nilai jumlah pembayaran listrik yang akan diprediksi oleh model.
- **Fitur (`X`)** → semua kolom selain `amount_paid`.  
  Fitur ini digunakan sebagai input yang akan dipelajari model untuk memprediksi target.

Langkah pemisahan ini penting karena algoritma Machine Learning membutuhkan data input (X) dan output/label (y) secara terpisah.
"""

# Target: amount_paid
# Features: semua kolom kecuali amount_paid

X = consumption.drop("amount_paid", axis=1)
y = consumption["amount_paid"]

"""### Membagi Dataset menjadi Data Latih dan Data Uji
Pada tahap ini, dataset dibagi menjadi dua bagian:
- **Data Latih (Training set)** → digunakan untuk melatih model (80% dari data).
- **Data Uji (Testing set)** → digunakan untuk menguji performa model pada data baru yang belum pernah dilihat (20% dari data).

Parameter yang digunakan:
- `test_size=0.2` → artinya 20% data akan digunakan untuk uji, 80% untuk latih.
- `random_state=42` → digunakan untuk memastikan hasil pembagian selalu konsisten (reproducible).
"""

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# MODEL DEVELOPMENT

### Melatih Model Linear Regression
Pada tahap ini, dibuat dan dilatih model regresi linear menggunakan data latih (`X_train`, `y_train`).

Langkah-langkah:
1. **Inisialisasi model** → `LinearRegression()`.
2. **Melatih model** → `fit(X_train, y_train)`.  
   Model akan mempelajari hubungan antara fitur (X) dan target (y).

Linear Regression mencoba memodelkan hubungan linier antara fitur-fitur input dengan target output.
"""

lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)

"""### Melakukan Prediksi dengan Model Linear Regression
Setelah model dilatih pada data latih, tahap selanjutnya adalah melakukan prediksi pada data uji.  

- `lin_reg.predict(X_test)` digunakan untuk menghasilkan nilai prediksi berdasarkan fitur pada data uji.
- Hasil prediksi disimpan dalam variabel `y_pred_lin`.  
- Nilai ini nantinya akan dibandingkan dengan `y_test` (nilai sebenarnya) untuk mengevaluasi performa model.

"""

# Prediksi
y_pred_lin = lin_reg.predict(X_test)

"""### Evaluasi Model Linear Regression
Setelah melakukan prediksi, tahap selanjutnya adalah mengevaluasi performa model dengan beberapa metrik:

- **MAE (Mean Absolute Error)** → rata-rata selisih absolut antara nilai sebenarnya (`y_test`) dan prediksi (`y_pred_lin`). Semakin kecil, semakin baik.
- **RMSE (Root Mean Squared Error)** → akar dari rata-rata kuadrat error. Memberi penalti lebih besar pada error yang besar.
- **R² Score (Koefisien Determinasi)** → mengukur seberapa baik model menjelaskan variasi data target.  
  - Nilai mendekati 1 → model sangat baik.
  - Nilai mendekati 0 → model kurang baik.

Evaluasi ini membantu mengetahui apakah model regresi linear sudah cukup baik atau perlu algoritma lain.

"""

# Evaluasi
print("\n=== Linear Regression Evaluation ===")
print("MAE:", mean_absolute_error(y_test, y_pred_lin))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_lin)))
print("R2 Score:", r2_score(y_test, y_pred_lin))

"""### Melatih dan Mengevaluasi Model Random Forest Regressor
Selain Linear Regression, digunakan juga algoritma **Random Forest Regressor** untuk membandingkan performa model.  

Langkah-langkah:
1. **Inisialisasi model** dengan `RandomForestRegressor()`.  
   - `n_estimators=100` → jumlah pohon keputusan (decision trees) yang digunakan adalah 100.  
   - `random_state=42` → memastikan hasil konsisten (reproducible).
2. **Melatih model** pada data latih menggunakan `fit(X_train, y_train)`.
3. **Prediksi** data uji menggunakan `predict(X_test)`.
4. **Evaluasi performa** model dengan metrik:
   - **MAE (Mean Absolute Error)**
   - **RMSE (Root Mean Squared Error)**
   - **R² Score (Koefisien Determinasi)**  

Random Forest biasanya memberikan hasil yang lebih baik dibandingkan Linear Regression karena dapat menangkap hubungan non-linear antar variabel.

"""

rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)
rf_reg.fit(X_train, y_train)


y_pred_rf = rf_reg.predict(X_test)


print("\n=== Random Forest Evaluation ===")
print("MAE:", mean_absolute_error(y_test, y_pred_rf))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_rf)))
print("R2 Score:", r2_score(y_test, y_pred_rf))

"""# VISUALISASI HASIL PREDIKSI VS NILAI AKTUAL

Pada tahap ini dibuat grafik *scatter plot* untuk membandingkan nilai aktual (`y_test`) dengan hasil prediksi dari dua model (Linear Regression dan Random Forest).  

- **Titik scatter** menunjukkan perbandingan antara nilai aktual dan nilai prediksi.  
  - Biru → hasil prediksi Random Forest.  
  - Oranye → hasil prediksi Linear Regression.  
- **Garis putus-putus hitam (y = x)** menunjukkan prediksi sempurna (nilai prediksi = nilai aktual).  
- Semakin dekat titik ke garis, semakin akurat prediksinya.  

Visualisasi ini membantu mengevaluasi performa model secara intuitif dan memperlihatkan model mana yang lebih mendekati garis ideal.
"""

plt.figure(figsize=(8,6))
plt.scatter(y_test, y_pred_rf, alpha=0.7, label="Random Forest")
plt.scatter(y_test, y_pred_lin, alpha=0.7, label="Linear Reg")
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title("Actual vs Predicted Electricity Bill")
plt.legend()
plt.show()

"""# FEATURE IMPORTANCE DARI RANDOM FOREST

### Analisis Feature Importance (Random Forest)
Random Forest memiliki kemampuan untuk menghitung **pentingnya setiap fitur** dalam membuat prediksi.  
Feature importance menunjukkan seberapa besar kontribusi sebuah variabel terhadap hasil prediksi model.  

Langkah-langkah:
1. Mengambil nilai **feature importance** dari model dengan `rf_reg.feature_importances_`.
2. Membuat DataFrame `feat_imp` yang berisi nama fitur dan skor pentingnya.
3. Mengurutkan fitur berdasarkan tingkat kepentingannya (descending).
4. Membuat **bar plot** menggunakan seaborn untuk memvisualisasikan kontribusi fitur.

Visualisasi ini membantu menjawab pertanyaan:  
👉 "Faktor apa yang paling berpengaruh terhadap jumlah pembayaran listrik (`amount_paid`)?"
"""

importances = rf_reg.feature_importances_
feature_names = X.columns


feat_imp = pd.DataFrame({"Feature": feature_names, "Importance": importances})
feat_imp = feat_imp.sort_values(by="Importance", ascending=False)


plt.figure(figsize=(10,6))
sns.barplot(x="Importance", y="Feature", data=feat_imp, palette="viridis")
plt.title("Feature Importance - Random Forest")
plt.show()